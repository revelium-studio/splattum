"""
RunPod Serverless Handler for SHARP ML Model
This handler receives image data, processes it with SHARP, uploads PLY to R2, and returns URL
"""

import base64
import os
import tempfile
import subprocess
from pathlib import Path
import json
import runpod
import boto3
from botocore.exceptions import ClientError
from datetime import datetime, timezone


def handler(job):
    """
    RunPod serverless handler function.
    
    Expected job input:
    {
        "id": "job_id",
        "input": {
            "image": "base64_encoded_image_string",
            "filename": "image.jpg"
        }
    }
    
    Returns:
    {
        "output": {
            "ply": "base64_encoded_ply_string",
            "plyBase64": "base64_encoded_ply_string",
            "filename": "image.ply"
        }
    }
    """
    try:
        # Extract input data from RunPod job
        job_input = job.get("input", {})
        image_b64 = job_input.get("image")
        filename = job_input.get("filename", "image.jpg")
        
        if not image_b64:
            return {
                "error": "No image provided in input"
            }
        
        print(f"üîÑ Processing image: {filename}")
        print(f"üì¶ Image base64 length: {len(image_b64)}")
        
        # Decode base64 image
        image_bytes = base64.b64decode(image_b64)
        print(f"‚úÖ Image decoded successfully ({len(image_bytes)} bytes)")
        
        # Set up environment for SHARP
        os.environ["TORCH_HOME"] = "/cache/torch"
        os.environ["HF_HOME"] = "/cache/huggingface"
        
        with tempfile.TemporaryDirectory() as tmpdir:
            # Save input image
            input_path = Path(tmpdir) / filename
            input_path.write_bytes(image_bytes)
            print(f"üíæ Saved input image to: {input_path}")
            
            # Output directory
            output_dir = Path(tmpdir) / "output"
            output_dir.mkdir()
            
            # Run SHARP processing
            print(f"üîÑ Starting SHARP processing...")
            result = subprocess.run(
                ["sharp", "predict", "-i", str(input_path), "-o", str(output_dir)],
                capture_output=True,
                text=True,
                timeout=600,  # 10 minute timeout
            )
            
            print("SHARP stdout:", result.stdout)
            if result.stderr:
                print("SHARP stderr:", result.stderr)
            
            if result.returncode != 0:
                error_msg = f"SHARP processing failed: {result.stderr}"
                print(f"‚ùå {error_msg}")
                return {
                    "error": error_msg
                }
            
            # Find the output PLY file
            ply_files = list(output_dir.glob("*.ply"))
            if not ply_files:
                error_msg = "No PLY file generated by SHARP"
                print(f"‚ùå {error_msg}")
                return {
                    "error": error_msg
                }
            
            # Read PLY file
            ply_path = ply_files[0]
            print(f"‚úÖ Found PLY file: {ply_path}")
            
            ply_bytes = ply_path.read_bytes()
            print(f"‚úÖ Processing completed successfully!")
            print(f"üì¶ PLY file size: {len(ply_bytes)} bytes")
            
            # Upload PLY file to R2 (Cloudflare S3-compatible storage)
            # RunPod has a ~10MB limit on job results, so we upload to R2 and return URL
            r2_account_id = os.environ.get("R2_ACCOUNT_ID", "")
            r2_access_key_id = os.environ.get("R2_ACCESS_KEY_ID", "")
            r2_secret_access_key = os.environ.get("R2_SECRET_ACCESS_KEY", "")
            r2_bucket_name = os.environ.get("R2_BUCKET_NAME", "ml-sharp-outputs")
            r2_endpoint_url = os.environ.get("R2_ENDPOINT_URL", f"https://{r2_account_id}.r2.cloudflarestorage.com")
            r2_public_url = os.environ.get("R2_PUBLIC_URL", f"https://pub-{r2_account_id}.r2.dev")
            
            if not r2_account_id or not r2_access_key_id or not r2_secret_access_key:
                print("‚ö†Ô∏è R2 credentials not configured, falling back to base64 (may fail for large files)")
                ply_b64 = base64.b64encode(ply_bytes).decode("utf-8")
                if len(ply_b64) > 10 * 1024 * 1024:  # 10MB limit
                    return {
                        "error": f"PLY file too large ({len(ply_bytes)} bytes) and R2 not configured. Please configure R2_ACCOUNT_ID, R2_ACCESS_KEY_ID, and R2_SECRET_ACCESS_KEY."
                    }
                return {
                    "ply": ply_b64,
                    "plyBase64": ply_b64,
                    "filename": ply_path.name
                }
            
            # Upload to R2
            try:
                print(f"üì§ Uploading PLY to R2 bucket: {r2_bucket_name}")
                s3_client = boto3.client(
                    's3',
                    endpoint_url=r2_endpoint_url,
                    aws_access_key_id=r2_access_key_id,
                    aws_secret_access_key=r2_secret_access_key,
                    region_name='auto'  # R2 doesn't use regions
                )
                
                # Generate unique filename with timestamp
                timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
                r2_key = f"ply/{timestamp}_{ply_path.name}"
                
                # Upload file
                s3_client.put_object(
                    Bucket=r2_bucket_name,
                    Key=r2_key,
                    Body=ply_bytes,
                    ContentType='application/octet-stream'
                )
                
                # Generate public URL
                ply_url = f"{r2_public_url}/{r2_key}"
                print(f"‚úÖ Uploaded to R2: {ply_url}")
                
                return {
                    "plyUrl": ply_url,
                    "url": ply_url,  # Alternative key
                    "filename": ply_path.name,
                    "size": len(ply_bytes)
                }
            except ClientError as e:
                error_msg = f"Failed to upload to R2: {str(e)}"
                print(f"‚ùå {error_msg}")
                return {
                    "error": error_msg
                }
            except Exception as e:
                error_msg = f"R2 upload error: {str(e)}"
                print(f"‚ùå {error_msg}")
                return {
                    "error": error_msg
                }
            
    except subprocess.TimeoutExpired:
        error_msg = "SHARP processing timed out after 10 minutes"
        print(f"‚ùå {error_msg}")
        return {
            "error": error_msg
        }
    except Exception as e:
        error_msg = f"Error processing image: {str(e)}"
        print(f"‚ùå {error_msg}")
        import traceback
        traceback.print_exc()
        return {
            "error": error_msg
        }


# Register handler with RunPod serverless SDK
if __name__ == "__main__":
    runpod.serverless.start({"handler": handler})
